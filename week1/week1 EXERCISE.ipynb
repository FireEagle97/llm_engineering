{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import ollama\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Initialize and constants\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "# constants \n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "MODEL_LLAMA = 'llama3.2:1b'\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08a914a-4928-4264-a7e2-03d20ed17fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 74701a8c35f6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.3 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 4f659a1e86d7... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5b78e1-f85a-4b5c-b9e8-1ab8064c1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful technical tutor who answers questions about python code, software engineering, data science and LLMs only\"\n",
    "user_prompt = \"Please give a detailed explanation of the following question:\" + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc149c7e-5c56-4a6c-8454-0808781f3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def get_gpt_answer():\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07ddeac0-184e-4889-bd57-1e5425018b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break down the given code snippet: `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`.\n",
       "\n",
       "### Explanation of the Components\n",
       "\n",
       "1. **Set Comprehension**: \n",
       "   - The expression `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension. This creates a set of unique authors from a list (or iterable) of `books`.\n",
       "   - `book.get(\"author\")` attempts to retrieve the value associated with the key \"author\" from each `book` dictionary.\n",
       "   - The comprehension iterates through each `book` in the `books` collection (which we can assume is a list of dictionaries or similar structures).\n",
       "   - The condition `if book.get(\"author\")` filters out any `book` entries where the `\"author\"` key does not exist or its value is `None`, ensuring that only valid authors are included.\n",
       "\n",
       "2. **The `yield from` Statement**:\n",
       "   - `yield from` is a statement used in Python's generator functions. It allows the generator to yield all values from an iterable (in this case, the set of authors) one by one.\n",
       "   - Using `yield from` is particularly useful for delegating the yielding process to another iterable while maintaining control within the generator function.\n",
       "\n",
       "### Purpose of the Code\n",
       "\n",
       "In the context of a generator function, this line of code does the following:\n",
       "\n",
       "- Collects all unique authors from the `books` list, effectively filtering out any books that do not have an author specified.\n",
       "- Each unique author is yielded one at a time to whoever is consuming the generator — for instance, it could be used in a loop to process each author separately.\n",
       "\n",
       "### Why Use This Code?\n",
       "\n",
       "- **Elimination of Duplicates**: By using a set comprehension, the code automatically ensures that each author is unique in the results. If two or more books are by the same author, only one instance of that author's name will be yielded.\n",
       "- **Efficiency**: The `yield from` construct is efficient for producing a series of values and is particularly useful when working with large datasets or streams of data, allowing the consumer of the generator to process each author as they are needed without having to load everything into memory at once.\n",
       "\n",
       "### Example Walkthrough\n",
       "\n",
       "Suppose you have the following list of `books`:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book A\", \"author\": \"Author 1\"},\n",
       "    {\"title\": \"Book B\", \"author\": \"Author 2\"},\n",
       "    {\"title\": \"Book C\", \"author\": \"Author 1\"},\n",
       "    {\"title\": \"Book D\"},  # No author\n",
       "    {\"title\": \"Book E\", \"author\": \"Author 3\"},\n",
       "]\n",
       "\n",
       "\n",
       "When you run the comprehension part:\n",
       "\n",
       "python\n",
       "{book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "You would get a set: `{\"Author 1\", \"Author 2\", \"Author 3\"}`.\n",
       "\n",
       "Then, if this code is part of a generator function and you call that generator, each time the generator is iterated over, it would yield each of these authors:\n",
       "\n",
       "- \"Author 1\"\n",
       "- \"Author 2\"\n",
       "- \"Author 3\"\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "This code efficiently extracts unique authors from a collection of book dictionaries while filtering out entries that do not have an associated author. It's an example of combining set comprehensions with Python's generator capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_gpt_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This line of code uses Python's built-in `yield from` statement, which is a feature introduced in Python 3.10. Here's a breakdown of what it does:\n",
       "\n",
       "1. `books`: This variable is expected to be an iterable (such as a list, tuple, or dictionary) that contains objects with the attribute `get(\"author\")`.\n",
       "2. The expression `{book.get(\"author\") for book in books}` generates a new iterable containing the authors' names.\n",
       "3. `yield from`: This keyword returns generators (i.e., iterables that can be used to generate values on-the-fly). It takes an iterable (in this case, the result of the previous expression) and returns a generator expression.\n",
       "\n",
       "So, what's happening here?\n",
       "\n",
       "- The code first gets all authors' names for each book in `books` using a generator expression.\n",
       "- It then uses `yield from` to return this generated list as a new iterable. This means that when the outer loop (which iterates over the `books` iterable) finishes, it will yield each author's name one at a time.\n",
       "\n",
       "Why is this useful?\n",
       "\n",
       "- The code doesn't have to load all authors' names into memory at once.\n",
       "- It can handle large datasets without running out of memory.\n",
       "- It allows for efficient iteration over the data, as the results are generated on-the-fly rather than loaded into memory upfront.\n",
       "\n",
       "Here's an example to illustrate how it works:\n",
       "\n",
       "```python\n",
       "books = [\n",
       "    {\"author\": \"Author1\", \"title\": \"Book1\"},\n",
       "    {\"author\": \"Author2\", \"title\": \"Book2\"},\n",
       "    {\"author\": \"Author3\", \"title\": \"Book3\"}\n",
       "]\n",
       "\n",
       "for author in yield from books:\n",
       "    print(author)\n",
       "\n",
       "# Output:\n",
       "# Author1\n",
       "# Author2\n",
       "# Author3\n",
       "```\n",
       "\n",
       "In this example, we have a list of dictionaries where each dictionary represents a book with an `author` key. We use the generator expression to get the authors' names for each book and then iterate over the resulting iterable.\n",
       "\n",
       "This code is likely used in a data processing or data analysis pipeline where you need to process large datasets of books. The `yield from` statement makes it efficient and scalable, especially when dealing with large datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to \n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "reply = response['message']['content'] \n",
    "display(Markdown(reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716553ad-76f1-47ca-99b5-c2249c66cc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
